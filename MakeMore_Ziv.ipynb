{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhdPqTNfuC2QnpPr1zz8jR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ziv6095/prophet/blob/master/MakeMore_Ziv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are building an LLM model for names. The txt file contain ~32000 names and we will generate \"new\" names. Note that the dataset is taken from the file names.txt in which I uploaded to the files folder.\n"
      ],
      "metadata": {
        "id": "00cGP-Puu95n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = open('names.txt', 'r').read().splitlines()\n"
      ],
      "metadata": {
        "id": "jduRZulWvGTx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words[:100]\n"
      ],
      "metadata": {
        "id": "s15GOoh0vLrR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2cfeacd-d79f-44bd-e41a-cc087e7fdd6e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['emma',\n",
              " 'olivia',\n",
              " 'ava',\n",
              " 'isabella',\n",
              " 'sophia',\n",
              " 'charlotte',\n",
              " 'mia',\n",
              " 'amelia',\n",
              " 'harper',\n",
              " 'evelyn',\n",
              " 'abigail',\n",
              " 'emily',\n",
              " 'elizabeth',\n",
              " 'mila',\n",
              " 'ella',\n",
              " 'avery',\n",
              " 'sofia',\n",
              " 'camila',\n",
              " 'aria',\n",
              " 'scarlett',\n",
              " 'victoria',\n",
              " 'madison',\n",
              " 'luna',\n",
              " 'grace',\n",
              " 'chloe',\n",
              " 'penelope',\n",
              " 'layla',\n",
              " 'riley',\n",
              " 'zoey',\n",
              " 'nora',\n",
              " 'lily',\n",
              " 'eleanor',\n",
              " 'hannah',\n",
              " 'lillian',\n",
              " 'addison',\n",
              " 'aubrey',\n",
              " 'ellie',\n",
              " 'stella',\n",
              " 'natalie',\n",
              " 'zoe',\n",
              " 'leah',\n",
              " 'hazel',\n",
              " 'violet',\n",
              " 'aurora',\n",
              " 'savannah',\n",
              " 'audrey',\n",
              " 'brooklyn',\n",
              " 'bella',\n",
              " 'claire',\n",
              " 'skylar',\n",
              " 'lucy',\n",
              " 'paisley',\n",
              " 'everly',\n",
              " 'anna',\n",
              " 'caroline',\n",
              " 'nova',\n",
              " 'genesis',\n",
              " 'emilia',\n",
              " 'kennedy',\n",
              " 'samantha',\n",
              " 'maya',\n",
              " 'willow',\n",
              " 'kinsley',\n",
              " 'naomi',\n",
              " 'aaliyah',\n",
              " 'elena',\n",
              " 'sarah',\n",
              " 'ariana',\n",
              " 'allison',\n",
              " 'gabriella',\n",
              " 'alice',\n",
              " 'madelyn',\n",
              " 'cora',\n",
              " 'ruby',\n",
              " 'eva',\n",
              " 'serenity',\n",
              " 'autumn',\n",
              " 'adeline',\n",
              " 'hailey',\n",
              " 'gianna',\n",
              " 'valentina',\n",
              " 'isla',\n",
              " 'eliana',\n",
              " 'quinn',\n",
              " 'nevaeh',\n",
              " 'ivy',\n",
              " 'sadie',\n",
              " 'piper',\n",
              " 'lydia',\n",
              " 'alexa',\n",
              " 'josephine',\n",
              " 'emery',\n",
              " 'julia',\n",
              " 'delilah',\n",
              " 'arianna',\n",
              " 'vivian',\n",
              " 'kaylee',\n",
              " 'sophie',\n",
              " 'brielle',\n",
              " 'madeline']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(words))\n",
        "print(min(len(w) for w in words))\n",
        "print(max(len (w) for w in words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvUTih1o01q-",
        "outputId": "a1419cb4-b92c-4de6-e7cf-4ba489ca91b3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32033\n",
            "2\n",
            "15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first model we are building is bigram - This model only predict the letter based ONLY on the previous letter. We want to hold a 2D array with the probability of each one of the 26 letters to be followed by each one of the letters. We would add <.> and <.> for starting a name and ending a name."
      ],
      "metadata": {
        "id": "YsdaNHILTb9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch #pytorch"
      ],
      "metadata": {
        "id": "CS8zuig_UCgI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = torch.zeros((28,28), dtype=torch.int32) #2D torch array of zeros where data type is int32."
      ],
      "metadata": {
        "id": "ym5wuDnU1uyr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(\"\".join(words)))) #joins all the elements in the words list into a single string without any seperators. set keeps only the unieqe. List converts the set back into a list. The reason for this conversion is that sets in Python are unordered, so if you need to preserve or establish a specific order (like alphabetical), you need to use a list.\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)} #string to integer\n",
        "stoi['.']= 0  #We want to set the special letter of starting and ending a word at index 0 fo conviance.\n",
        "\n",
        "\n",
        "#WE now have the full conversion from string to integer"
      ],
      "metadata": {
        "id": "x67aqV1gdV6C"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for w in words: #For every name in our file\n",
        "  chs = ['.'] + list(w) +['.'] # list(w) will create a list where each element is a character from the name (e.g. 'emma' ->['e','m','m','a'])\n",
        "  #The zip function takes two or more iterables (like lists) and returns an iterator that aggregates elements from each of the iterables. Here it is used to pair each element in chs with its subsequent element. So, if chs is [a, b, c, d], zip(chs, chs[1:]) pairs a with b, b with c, and c with d. The last element (d in this case) is not paired with anything because there is no subsequent element.\n",
        "  for ch1, ch2 in zip (chs, chs[1:]):\n",
        "    ix1 = stoi[ch1] #covert the charcther to its integer\n",
        "    ix2 = stoi[ch2]\n",
        "    N[ix1, ix2] += 1 #We count +1 of the cases where ch2 is coming after ch1.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PUpbzcHefRLI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we want to converate the count into probabilities"
      ],
      "metadata": {
        "id": "fuzJIzXql06P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p = N[0].float()\n",
        "p = p / p.sum()\n",
        "p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-X9-yLRl6TW",
        "outputId": "c05e9d75-b059-4028-db05-d341f19136d6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.1377, 0.0408, 0.0481, 0.0528, 0.0478, 0.0130, 0.0209, 0.0273,\n",
              "        0.0184, 0.0756, 0.0925, 0.0491, 0.0792, 0.0358, 0.0123, 0.0161, 0.0029,\n",
              "        0.0512, 0.0642, 0.0408, 0.0024, 0.0117, 0.0096, 0.0042, 0.0167, 0.0290,\n",
              "        0.0000])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}